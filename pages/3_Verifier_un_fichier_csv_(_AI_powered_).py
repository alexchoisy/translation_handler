# 3_Verifier_un_fichier_csv_(_AI_powered_).py

import json
import sys
import os
import time
import dotenv as denv

# Ajouter le r√©pertoire contenant utils.py au sys.path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(os.path.join(project_root, 'functions'))

from openai import OpenAI
import streamlit as st
from utils import chunk_csv, csv_chunk_to_verified_translations, enableDisable, estimate_number_of_tokens, estimate_number_of_tokens_ia, merge_verified_translations, propose_translations_deepl, transform_dataframe, transform_json, verify_by_AI, verify_by_openAI
import pandas as pd
import os
import requests
# disable ssl warnings for dev purposes
from urllib3.exceptions import InsecureRequestWarning

# Suppress only the single warning from urllib3 needed.
requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)

denv.load_dotenv()

st.set_page_config(page_title="V√©rifier un fichier CSV (AI powered)", page_icon="üìÇ", layout="wide")

openAIAPIKey = os.getenv('OPENAI_API_KEY')
deepLAPIKEY = os.getenv('DEEPL_API_KEY')
baseUrl = os.getenv('OPENLLM_BASE_URL')

if "form_sending" not in st.session_state:
    st.session_state.form_sending = False

st.title('V√©rifier un fichier CSV (AI powered)')

st.markdown(
    """
    Cette application permet de fournir un fichier csv contenant des labels aupr√®s d'une IA pour en v√©rifier le contenu.\n
    Plusieurs mod√®les d'IA sont disponibles, via OpenAI ou via un service intranet.\n
    Les instructions de v√©rification sont les suivantes :\n
    - Une traduction ne doit pas √™tre vide\n
    - Une traduction doit appartenir au lexique de la langue indiqu√©e\n
    - Une traduction doit correspondre √† la valeur source pour la langue indiqu√©e\n
"""
)

mainTab, logTab = st.tabs(['üß† Application', 'üî® Debug'])

# D√©claration de la boite √† logs
st.session_state.full_debug = False
logBox = logTab.expander(label='Logs', expanded=True)
st.session_state.logBox = logBox

with mainTab:
    # Champ pour indiquer le s√©parateur utilis√© pour le fichier CSV
    separator = st.text_input('Entrez le s√©parateur utilis√© pour le fichier CSV (par d√©faut ",") :', ',', disabled=st.session_state.form_sending)

    # T√©l√©verser un fichier CSV
    csv_file = st.file_uploader('T√©l√©verser un fichier CSV :', type='csv', disabled=st.session_state.form_sending)

    if csv_file:
        # Lire le fichier CSV
        df = pd.read_csv(csv_file, sep=separator)
        jsonVal = df.to_json()
        # Convertir jsonVal en dictionnaire
        jsonVal = json.loads(jsonVal)

        if st.session_state.full_debug:
            logBox.json(jsonVal, expanded=False)

        # Extraire les langues √† partir des en-t√™tes du fichier CSV
        languages = df.columns[2:]
        targetLanguages = [lang for lang in languages if lang != 'fr']
        jsonTransformed = transform_json(jsonVal, 'fr', targetLanguages)

        melted = transform_dataframe(df.drop(labels='Domain',axis=1), 'fr', targetLanguages)

        if st.session_state.full_debug:
            logBox.code(melted)

        st.caption(f":gray[Estimation du nombre de tokens contenus dans le fichier : {estimate_number_of_tokens(melted.to_csv(index=False))}]")

    exampleSet = {
        "Key": ["label.test"],
        "Domain": ["messages"],
        "fr": ["Test FR"],
        "en": ["Test EN"],
        "es": ["Test ES"],
        "de": ["Test DE"]
    }
    with st.container():
        st.caption('Exemple de fichier CSV :')
        st.table(exampleSet)

    optIA = st.toggle('Utiliser un mod√®le IA pour d√©tecter les erreurs de traductions', disabled=st.session_state.form_sending)
    if optIA:
        with st.container(border=True):
            selected_source = st.selectbox('Choisir une source :', [{"key":"fake","label":'POC Mode ( Fake IA verification )'}, {"key":"openai","label":'OpenAI API ( Internet )'}, {"key":"local", "label":"Serveur local Ollama"}], format_func=(lambda opt: opt["label"]), placeholder='Choisir une option', disabled=st.session_state.form_sending)

            if selected_source["key"] == 'fake':
                selected_model = 'fake'

            if selected_source["key"] == 'local':
                # R√©cup√©rer la liste des mod√®les disponibles depuis l'API Ollama
                response = requests.get(baseUrl+'tags', verify=False)
                models = response.json()['models']

                # Ajouter un s√©lecteur pour choisir un mod√®le d'IA
                selected_model = st.selectbox('Choisir un mod√®le d\'IA :', [model['name'] for model in models], disabled=st.session_state.form_sending)

            if selected_source["key"] == 'openai':
                client = OpenAI(api_key=openAIAPIKey)
                my_assistants = client.beta.assistants.list(
                    order="desc",
                    limit="20",
                )
                models = [
                    {
                        "type": "model",
                        "label": "gpt-3.5-turbo",
                        "id": "gpt-3.5-turbo"
                    },
                    {
                        "type": "model",
                        "label": "gpt-4-turbo-preview",
                        "id": "gpt-4-turbo-preview"
                    },

                ]
                for assistant in my_assistants.data:
                    models.append({
                        "type": "assistant",
                        "label": assistant.name,
                        "id": assistant.id
                    })

                selected_model = st.selectbox('Choisir un mod√®le d\'IA :', models, format_func=(lambda opt: opt["label"]+" ("+opt["type"]+ ")"), disabled=st.session_state.form_sending)

            max_tokens = st.number_input(label="Nombre maximum de tokens par paquet (Chunk) :", value=2000, step=1, min_value=250, disabled=st.session_state.form_sending)
            st.caption(f":gray[Estimation du nombre de tokens utilis√©s : {estimate_number_of_tokens_ia(melted.to_csv(index=False), max_tokens=max_tokens)}]")

            # Ajouter un toggle pour les propositions deepL
            optDeepL = st.toggle('Utiliser DeepL pour proposer des corrections de traductions', disabled=st.session_state.form_sending)

    # Activation du mode debug complet. Ne pas utiliser sur de larges datasets
    full_debug = st.toggle("Activer le mode debug complet (√† utiliser uniquement sur de petits datasets) :", disabled=st.session_state.form_sending)

    if st.button('Envoyer',on_click=enableDisable, args=("form_sending",True), disabled=st.session_state.form_sending) and csv_file:
        # D√©claration de la boite √† logs
        st.session_state.full_debug = full_debug

        start_time = time.time()

        status = st.status("Transformation des donn√©es...", expanded=True)

        if optIA and selected_model:

            logBox.write("Chunking CSV Datas...")
            chunks = chunk_csv(melted.to_csv(index=False), max_tokens=max_tokens)
            logBox.write("Nombre de chunks g√©n√©r√©s : "+str(len(chunks)))
            
            status.write("Transformation des donn√©es  ‚úîÔ∏è")
            status.update(label="D√©tection des lignes malform√©es...")

            if st.session_state.full_debug:
                logBox.write("Affichage des 10 premiers chunks : ")
                for idx, chunk in enumerate(chunks[:10]):
                    logBox.write(f"Chunk n¬∞{idx}")
                    logBox.code(chunk)

            if selected_source["key"] == 'fake':
                verified_translations = {
                    "label.admin": {
                        "source_fr": "Administration",
                        "translations": [
                        {
                            "target_language": "de",
                            "value": "Admin Konsole",
                            "output": "OK"
                        },
                        {
                            "target_language": "en",
                            "value": "Admin Console",
                            "output": "OK"
                        },
                        {
                            "target_language": "es",
                            "value": "Administraci√≥n",
                            "output": "OK"
                        }
                        ]
                    },
                    "label.users": {
                        "source_fr": "Utilisateurs",
                        "translations": [
                        {
                            "target_language": "de",
                            "value": "Benutzer",
                            "output": "OK"
                        },
                        {
                            "target_language": "en",
                            "value": "Apples",
                            "output": "ERR: Incorrect translation"
                        },
                        {
                            "target_language": "es",
                            "value": "Usuarios",
                            "output": "OK"
                        }
                        ]
                    },
                    "label.referentiels": {
                        "source_fr": "R√©f√©rentiels",
                        "translations": [
                        {
                            "target_language": "de",
                            "value": "Rahmenwerke",
                            "output": "OK"
                        },
                        {
                            "target_language": "en",
                            "value": "MemePasDeLanglais",
                            "output": "ERR: Invalid content"
                        },
                        {
                            "target_language": "es",
                            "value": "Referenciales",
                            "output": "OK"
                        }
                        ]
                    },
                    "label.organisations": {
                        "source_fr": "Organisations",
                        "translations": [
                        {
                            "target_language": "de",
                            "value": "",
                            "output": "ERR: Empty value"
                        },
                        {
                            "target_language": "en",
                            "value": "Organisations",
                            "output": "OK"
                        },
                        {
                            "target_language": "es",
                            "value": "",
                            "output": "ERR: Empty value"
                        }
                        ]
                    }
                }
                status.write("D√©tection des lignes malform√©es  ‚úîÔ∏è")

            # D√©tecter les erreurs dans les lignes
            if selected_source["key"] == "local":
                for cpt, chunk in enumerate(chunks):
                    status.update(label=f"D√©tection des lignes malform√©es... Chunk n¬∞{cpt} sur {str(len(chunks))}")
                    verified_chunk = verify_by_AI(chunk, baseUrl, selected_model)
                    verified_translations.update(verified_chunk)
                status.write("D√©tection des lignes malform√©es  ‚úîÔ∏è")
                # st.json(verified_translations)

            # Tests openAI :
            if selected_source["key"] == "openai" and selected_model:
                verified_translations = {}
                for cpt, chunk in enumerate(chunks):
                    status.update(label=f"D√©tection des lignes malform√©es... Chunk n¬∞{cpt} sur {str(len(chunks))}")
                    verified_chunk = verify_by_openAI(chunk, openAIAPIKey, selected_model)
                    verified_translations.update(csv_chunk_to_verified_translations(verified_chunk=verified_chunk, df=df))

                status.write("D√©tection des lignes malform√©es  ‚úîÔ∏è")

            # st.write('WRITING JSON verified_translations')
            # st.json(verified_translations, expanded=False)

            df = merge_verified_translations(jsonVal, verified_translations, 'fr', targetLanguages)

            if optDeepL:
                status.update(label="G√©n√©ration des propositions de traduction...")

                verified_translations = propose_translations_deepl(verified_translations, deepLAPIKEY, 'fr', targetLanguages)
                # st.write('Retour deepl :')
                # st.json(verified_translations, expanded=False)

                df = merge_verified_translations(jsonVal, verified_translations, 'fr', targetLanguages, True)

                status.write("G√©n√©ration des propositions de traduction  ‚úîÔ∏è")

        elapsed_time = time.time() - start_time
        time.sleep(1)
        status.update(label=f"Termin√© ! (Total : {elapsed_time} secondes)", state="complete", expanded=True)

        if 'tokens_count' in st.session_state:
            st.caption(f"Nombre total de tokens utilis√©s : {st.session_state.tokens_count}")

        # Afficher le contenu du fichier CSV sous forme de tableau
        st.write('Fichier CSV :')
        st.dataframe(data=df,use_container_width=True)

        st.session_state.form_sending = False